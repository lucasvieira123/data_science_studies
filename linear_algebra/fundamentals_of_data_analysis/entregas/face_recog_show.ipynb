{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento de Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, os imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E algumas funções auxiliares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_row_vec(a, r=112, c=92):\n",
    "    return np.reshape( a, (1, r*c), order='C')\n",
    "\n",
    "def to_array(v, r=112, c=92):\n",
    "    return np.reshape( v, (r,c) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ler as imagens e colocá-las numa matriz de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: \n",
      "X_train:  (360, 10304)    y_train: (360,) \n",
      "X_test:   (40, 10304)     y_test:   (40,)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/thelmo/uece/cursos/analise_de_dados/\"\n",
    "PATH = PATH+\"jupyter/datasets/orl-faces/s{:d}/{:d}.pgm\"\n",
    "\n",
    "# ORL images are 112x92\n",
    "rows = 112\n",
    "cols = 92\n",
    "m = rows * cols\n",
    "ind = 40 # number of individuals\n",
    "pic = 10 # number of images per individual\n",
    "\n",
    "X_orig = np.empty( (1,m) )\n",
    "for d in range(1,ind+1):\n",
    "    for f in range(1,pic+1):\n",
    "        im_file = PATH.format(d, f)\n",
    "        img = to_row_vec( np.array( mpimg.imread(im_file) / 255.0 ) )\n",
    "        X_orig = np.vstack( (X_orig, img) )\n",
    "X_orig = np.delete(X_orig, 0, 0) # remove first row of zeros\n",
    "\n",
    "# Create array with train and test data\n",
    "X_train = np.copy(X_orig)\n",
    "X_test = np.zeros((ind,m))\n",
    "y_train = np.zeros((pic*ind,), dtype=int)\n",
    "y_test = np.zeros((ind,), dtype=int)\n",
    "for i in range(ind):\n",
    "    X_test[i,:] = X_orig[pic*i,:]\n",
    "    y_test[i] = i + 1\n",
    "    y_train[pic*i:pic*(i+1)] = i + 1 \n",
    "for i in range(ind-1,-1,-1):\n",
    "    X_train = np.delete(X_train, pic*i, axis=0)\n",
    "    y_train = np.delete(y_train, pic*i)\n",
    "print('Dimensões: \\nX_train: ', X_train.shape, \\\n",
    "      '   y_train:', y_train.shape, \\\n",
    "      '\\nX_test:  ', X_test.shape, \\\n",
    "      '    y_test:  ', y_test.shape)\n",
    "ntrains = X_train.shape[0]\n",
    "ntests = X_test.shape[0]\n",
    "\n",
    "# Remove mean\n",
    "mu_train = np.mean(X_train, axis=1)\n",
    "X_train = ( X_train.T - mu_train ).T\n",
    "mu_test = np.mean(X_test, axis=1)\n",
    "X_test = ( X_test.T - mu_test ).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos a Decomposição de Valor Singular de $X_{train}$.<br>\n",
    "Atenção para as dimensões da decompoisção reduzida:<br>\n",
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "X & = & U & S & V^T \\\\\n",
    "(360 \\times 10304) & & (360 \\times 360) & (360 \\times 360) \n",
    "& (360 \\times 10304) \n",
    "\\end{array}\n",
    "\\, .\n",
    "$$\n",
    "A matriz $V$, que é igual à matriz dos autovetores da matriz de covariância dos dados $Q$,<br>\n",
    "está sem as colunas correspondentes aos autovetores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: U:  (360, 360) , S:  (360,) , Vt:  (360, 10304)\n",
      "Variabilidade acumulada: 95.03%, até o 136-ésimo autovalor.\n"
     ]
    }
   ],
   "source": [
    "# Calculate SVD of X_train\n",
    "U, S, Vt = np.linalg.svd(X_train, full_matrices=False)\n",
    "print('Dimensões: U: ', U.shape, ', S: ', S.shape, ', Vt: ', Vt.shape)\n",
    "energy = np.cumsum(S**2) / np.sum(S**2)\n",
    "\n",
    "thres = 0.95 #0.83 # 0.95 # 0.80\n",
    "\n",
    "idx = [ n for n, i in enumerate(energy) if i > thres ][0]\n",
    "print( 'Variabilidade acumulada: {:.2f}%, até o {:d}-ésimo autovalor.'\\\n",
    "      .format(100 * energy[idx], idx) )\n",
    "\n",
    "# w, Q = np.linalg.eigh(np.cov(X_train, rowvar=False))\n",
    "# print(w.shape, Q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas são as 20 primeiras <i>eigenfaces</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "fig.suptitle('As 20 Primeiras Eigenfaces')\n",
    "\n",
    "for i in range(20):\n",
    "    sub = fig.add_subplot(4, 5, i + 1)\n",
    "    sub.imshow(to_array(Vt[i,:]), cmap='gray')\n",
    "    sub.set_xticks([])\n",
    "    sub.set_yticks([])\n",
    "    sub.set_xticklabels([])\n",
    "    sub.set_yticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Façamos a redução de dimensionalidade propriamente dita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões: \n",
      "X_train: (360, 10304) --> Y_train:  (360, 28)\n",
      "X_test:   (40, 10304) --> Y_test:    (40, 28)\n",
      "V:       (10304, 360) --> V_hat: (10304, 28)\n"
     ]
    }
   ],
   "source": [
    "# idx = 28\n",
    "V_hat  = Vt[:idx,:].T # Cuidado: V e não Vt\n",
    "# Y_train = U[:,:idx] * S[:idx] # Y = X V = U S Vt V = U S\n",
    "Y_train = np.dot( X_train, V_hat )\n",
    "# print(np.max(np.abs(Y_train - Y_train2)))\n",
    "Y_test  = np.dot( X_test,  V_hat )\n",
    "\n",
    "print( 'Dimensões: \\nX_train: {:} --> Y_train:  {:}'\\\n",
    "      .format(X_train.shape, Y_train.shape) )\n",
    "print( 'X_test:   {:} --> Y_test:    {:}'\\\n",
    "      .format(X_test.shape, Y_test.shape) )   \n",
    "print( 'V:       {:} --> V_hat: {:}'\\\n",
    "      .format(Vt.T.shape, V_hat.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um teste inicial para calcular a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de erros: 1 (id# [35]). \n",
      "Acurácia: 97.50%.\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "error_ids = []\n",
    "for i in range(ntests):\n",
    "    dist = []\n",
    "    for k in range(ntrains):\n",
    "        dist = np.append(dist, np.linalg.norm(Y_test[i,:] - Y_train[k,:]))\n",
    "    index = np.argmin(dist)\n",
    "    if y_train[index]!=y_test[i]:\n",
    "#     if index//9 != i:\n",
    "        error_count += 1\n",
    "        error_ids.append(i+1)\n",
    "print( 'Número de erros: {:d} (id# {:}). \\nAcurácia: {:.2f}%.'\\\n",
    "      .format(error_count, error_ids, 100 * (ind - error_count) / ind) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, procedemos com o reconhecimento propriamente dito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identidade real:      2 \n",
      "Identidade estimada:  2 (índice = 10 \b)\n"
     ]
    }
   ],
   "source": [
    "# Select new test image to be recognized,\n",
    "# from 1 to 40 (errors: 1 and 35).\n",
    "new_face = 2\n",
    "\n",
    "# Restore means\n",
    "X_train_show = (X_train.T + mu_train).T\n",
    "X_test_show  = (X_test.T  + mu_test).T\n",
    "\n",
    "# Esta tentativa faz os cálculos ANTES de mostrar as imagens.\n",
    "# O range do loop abaixo deve ser range(ntrains+1)\n",
    "#dist = []\n",
    "#for k in range(ntrains):\n",
    "#    dist = np.append(dist, np.linalg.norm(Y_test[new_face-1,:] - Y_train[k,:]))\n",
    "#index = np.argmin(dist)\n",
    "#print('Identidade real:     ', new_face, \\\n",
    "#      '\\nIdentidade estimada: ', index//9 + 1, '(index =', index, '\\b)')\n",
    "# Append result image to X_train_show\n",
    "#X_train_show = np.vstack( (X_train_show, X_train_show[index,:]) )\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(to_array(X_test_show[new_face-1,:]), cmap='gray')\n",
    "ax1.set_title('Nova Imagem (Teste)')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticklabels([])\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_title('Imagem Mais Similar')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "dist = []\n",
    "im = plt.imshow(np.random.randn(rows,cols), vmin=0, vmax=1, cmap='gray')\n",
    "plt.ion()\n",
    "for k in range(ntrains):\n",
    "    dist = np.append(dist, np.linalg.norm(Y_test[new_face-1,:] - Y_train[k,:]))\n",
    "    A = to_array(X_train_show[k,:])\n",
    "    im.set_data(A)\n",
    "    plt.pause(0.005)\n",
    "index = np.argmin(dist)\n",
    "print('Identidade real:     ', new_face, \\\n",
    "      '\\nIdentidade estimada: ', y_train[index], \\\n",
    "      '(índice =', index, '\\b)')\n",
    "im.set_data( to_array(X_train_show[index,:]) )\n",
    "plt.pause(0.005)\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos as imagens usadas pelo computador na busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identidade real:      2 \n",
      "Identidade estimada:  2 (índice = 10 \b)\n"
     ]
    }
   ],
   "source": [
    "# Select new test image to be recognized,\n",
    "# from 1 to 40 (errors: 1 and 35).\n",
    "new_face = 2\n",
    "\n",
    "# Reshape reduced images\n",
    "Y_train_show = np.dot( U[:,0:idx] * S[0:idx], Vt[0:idx,:] )\n",
    "Y_test_show  = np.dot( Y_test, V_hat.T )\n",
    "\n",
    "# Restore means\n",
    "X_train_show = (X_train.T + mu_train).T\n",
    "X_test_show  = (X_test.T  + mu_test).T\n",
    "Y_train_show = (Y_train_show.T + mu_train).T\n",
    "Y_test_show  = (Y_test_show.T + mu_test).T\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax1.imshow(to_array(X_test[new_face-1,:]), cmap='gray')\n",
    "ax1.set_title('Nova Imagem (Teste)')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticklabels([])\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax2.imshow(to_array(Y_test_show[new_face-1,:]), cmap='gray')\n",
    "ax2.set_title('Nova Imagem (Teste)')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ax3.set_title('Imagem Mais Similar')\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "ax3.set_xticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "dist = []\n",
    "im = plt.imshow(np.random.randn(rows,cols), vmin=0, vmax=1, cmap='gray')\n",
    "plt.ion()\n",
    "for k in range(ntrains):\n",
    "    dist = np.append(dist, np.linalg.norm(Y_test[new_face-1,:] - Y_train[k,:]))\n",
    "    A = to_array(Y_train_show[k,:])\n",
    "    im.set_data(A)\n",
    "    plt.pause(0.005)\n",
    "index = np.argmin(dist)\n",
    "print('Identidade real:     ', new_face, \\\n",
    "      '\\nIdentidade estimada: ', y_train[index], '(índice =', index, '\\b)')\n",
    "im.set_data( to_array(Y_train_show[index,:]) )\n",
    "plt.pause(0.005)\n",
    "plt.ioff()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos a acurácia desta execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de erros: 2 (id# [1, 35]). \n",
      "Acurácia: 95.00%.\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "error_ids = []\n",
    "for i in range(ntests):\n",
    "    dist = []\n",
    "    for k in range(ntrains):\n",
    "        dist = np.append(dist, np.linalg.norm(Y_test[i,:] - Y_train[k,:]))\n",
    "    index = np.argmin(dist)\n",
    "    if y_train[index]!=y_test[i]:\n",
    "        error_count += 1\n",
    "        error_ids.append(i+1)\n",
    "print( 'Número de erros: {:d} (id# {:}). \\nAcurácia: {:.2f}%.'\\\n",
    "      .format(error_count, error_ids, 100 * (ind - error_count) / ind) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OFFLINE: Podemos gerar os gráficos de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execução:   3.75 s.\n"
     ]
    }
   ],
   "source": [
    "def principal_components(r): # Y = X V = U S Vt V = U S\n",
    "    # Calcula as componentes principais:\n",
    "    V_hat  = Vt[:r,:].T # Cuidado: V e não Vt\n",
    "    Ytrain = U[:,:r] * S[:r] # Y = X V = U S Vt V = U S\n",
    "    Ytest  = np.dot( X_test,  V_hat )\n",
    "    return Ytrain, Ytest\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "@njit(fastmath=True, cache=True)\n",
    "def find_match(Ytrain, Ytest, ytrain, ytest, ntrains, ntests):\n",
    "    count = 0\n",
    "    for i in range(ntests):\n",
    "        min_dist = 10000\n",
    "        for j in range(ntrains):\n",
    "            dist = np.linalg.norm(Ytest[i,:] - Ytrain[j,:])\n",
    "            if dist <= min_dist:\n",
    "                index = j\n",
    "                min_dist = dist\n",
    "        if ytrain[index] == ytest[i]:\n",
    "            count += 1\n",
    "    return count / ntests\n",
    "           \n",
    "ntrains = 360\n",
    "ntests  = 40\n",
    "\n",
    "acc = []\n",
    "for r in range(1,360):\n",
    "    Y_train, Y_test = principal_components(r)\n",
    "    acc = np.append( acc, \\\n",
    "        find_match(Y_train, Y_test, y_train, y_test, ntrains, ntests) )\n",
    "\n",
    "elapsed = time() - start_time\n",
    "PATH = '/home/thelmo/uece/cursos/analise_de_dados/jupyter/'\n",
    "np.save(PATH+'orl_acc.npy', acc)\n",
    "\n",
    "print('Tempo de execução: {:6.2f} s.'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico a seguir aprensenta as acurácias obtidas para cada quantidade de autovetores retidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.load(PATH+'orl_acc.npy')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_title('Acurácia por Variabilidade Acumulada')\n",
    "ax1.set_xlabel('Números de Autovetores')\n",
    "ax1.set_ylabel('Acurácia (%)')\n",
    "ax1.plot(list(range(1,359)), acc[1:359])\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_title('Acurácia por Variabilidade Acumulada - Detalhe')\n",
    "ax2.set_xlabel('Números de Autovetores')\n",
    "ax2.set_ylabel('Acurácia (%)')\n",
    "ax2.plot(list(range(10,60)), acc[10:60])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NEM SEMPRE MAIS INFORMAÇÃO É MELHOR!</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

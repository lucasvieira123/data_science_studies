{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70f1f7d-1f7d-4b57-83d0-7512d0d23dd1",
   "metadata": {},
   "source": [
    " # 5 Methods of building models\n",
    " How to dicide which variables uses in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3503c-70e2-44bc-9c34-998981142d81",
   "metadata": {},
   "source": [
    "## 1. All-in\n",
    "- Prior knoledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fcae3-41a0-47bc-a96c-b606d14332fe",
   "metadata": {},
   "source": [
    "## 2. Stepwise Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429959d-80f1-40dc-8721-50f61af8e435",
   "metadata": {},
   "source": [
    "### 2.1. Backward Elimination\n",
    "- Step 1: select a significance level to stay in the model (e.g. SL = 0.05, \"p-value\")\n",
    "- Step 2: Fit the full model with all possible predictor (independent features)\n",
    "- Step 3: Consider the predictor (independent feature) with the highest P-value. If P>SL, go to STEP 4, otherwise go to FIN\n",
    "- Step 4: Remove the predictor (independent feature)\n",
    "- Step 5: Fit model without this variable\n",
    "- Step 6: Back to Step 3\n",
    "- FIN: Your Model Is Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40489ba7-6c2c-465c-8017-6a7e4c737c86",
   "metadata": {},
   "source": [
    "https://www.dropbox.com/sh/pknk0g9yu4z06u7/AADSTzieYEMfs1HHxKHt9j1ba?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303599ce-08c3-4e4f-a334-3ca8fba7dab0",
   "metadata": {},
   "source": [
    "Backward Elimination is irrelevant in Python, because the Scikit-Learn library automatically takes care of selecting the statistically significant features when training the model to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15daa45b-e226-4ae7-af2e-c8c2ea908f10",
   "metadata": {},
   "source": [
    "### 2.2. Forward Selection\n",
    "- Step 1: select a significance level to stay in the model (e.g. SL = 0.05, \"p-value\")\n",
    "- Step 2: For all simple regression models y ~ x_{n} Select the one with the lowset P-value (Fazer um regrassão com cada variavel indep)\n",
    "- Step 3: Keep this variable and fit all possible models with one extra predictor added to the one(s) you already have\n",
    "- Step 4: Consider the predictor with thw lowest P-value. If P < SL, go to Step 3, otherwise go to FIN\n",
    "- FIN: Your Model Is Ready\n",
    "\n",
    "Obs.: pode usar essa ideia de performace ao inves de p value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d16eb3-309c-41dd-8109-4fdb5e933a1f",
   "metadata": {},
   "source": [
    "Another way:\n",
    "The first step in Forward Feature Selection is to train n models using each feature individually and checking the performance. So if you have three independent variables, we will train three models using each of these three features individually.\n",
    "- It starts with the evaluation of each individual feature, and selects that which results in the best performing selected algorithm model.\n",
    "- What's the \"best?\" That depends entirely on the defined evaluation criteria (AUC, prediction accuracy, RMSE, etc.).\n",
    "- Next, all possible combinations of the that selected feature and a subsequent feature are evaluated, and a second feature is selected, and so on, until the required predefined number of features is selected.\n",
    "\n",
    "Obs.: pode usar essa ideia de performace ao inves de p value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc7912-7d65-440f-b19d-c49fd98aefb5",
   "metadata": {},
   "source": [
    "### 2.3. Bidirectional Elimination\n",
    "- Step 1: select a significance level to stay in the model (e.g. SL_IN = 0.05 and SL_OUT = 0.05)\n",
    "- Step 2: Perfom the next step of Forward Selection (new variables must have: P < SL_IN to enter)\n",
    "- Step 3: Perfom ALL steps of Backward Elimination (old variables must have P > SL_OUT is ready to exit the model)\n",
    "- Step 4: Go to Step 2\n",
    "- Step 5: No new variables can enter and no old variables can exit, Go to FIN\n",
    "- FIN: Your Model Is Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fd99c-8b2f-46bd-9777-b16c4b4ad975",
   "metadata": {},
   "source": [
    "## 3. Score Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465de8a-8478-41d4-8de6-2569d1a7f2f8",
   "metadata": {},
   "source": [
    "É o método que consome a maior quantidade de recursos\n",
    "For instance, 10 columns means 1023 models\n",
    "\n",
    "Obs.: Cada maneira diferente de treinar um modelo é considerado um modelo diferente. Faz sentido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa57c0-f644-401d-a23f-09d311fddbd6",
   "metadata": {},
   "source": [
    "- Step 1: Select a criterion of goodness of fit (e.g. Akaike criterion)\n",
    "- Step 2: Construct all Possible Regression Model: 2_^{n}-1 total combinations\n",
    "- Step 3: Select the one with the best criterion\n",
    "- FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38de548-a75f-46d0-ae8c-d6001e17978e",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/transfer_learning?hl=pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4ba6bf-575e-4759-8bf8-ee651298582e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-146fbcafb475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_dataset_from_directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191b030-ea4b-4544-aeac-d6ba687fa943",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a3654-3f4b-4827-8eb2-a87b09ef6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = image_dataset_from_directory(validation_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca922f-f82f-4ba6-bf90-f05a2d00f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bcaec-3d4a-4bb7-bcbc-0a0ce36ce3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51219-3c73-456d-85a4-857957ee409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68ef3b-ed26-41fd-b7dc-84461975c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49a83d-c1ad-4c22-8abe-2bf1a11de586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cc0d6-b2a0-4790-bf57-5b1528c281b7",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance\n",
    "https://www.tensorflow.org/guide/data_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cfafc-73f5-4efd-8270-00642d00ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f6025-adf8-4da8-9035-06041ba34c06",
   "metadata": {},
   "source": [
    "### Use data augmentation\n",
    "When you don't have a large image dataset, it's a good practice to artificially introduce sample diversity by applying random, yet realistic, transformations to the training images, such as rotation and horizontal flipping. This helps expose the model to different aspects of the training data and reduce overfitting.\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b0188-270d-4460-902f-a65036f51a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2eabc-b282-40fa-8d04-19fbf9d2b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68247f3f-5bfa-4763-b811-83f7825abbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This model expects pixel values in [-1, 1], but at this point, the pixel values in your\n",
    "#images are in [0, 255]. To rescale them, use the preprocessing method included with the model.\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f934d-4172-4ea5-8e99-49baef07b4ff",
   "metadata": {},
   "source": [
    "### Create the base model from the pre-trained convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535ed81-4662-4638-8966-9c849a8f6adb",
   "metadata": {},
   "source": [
    "You will create the base model from the MobileNet V2 model developed at Google. This is pre-trained on the ImageNet dataset, a large dataset consisting of 1.4M images and 1000 classes. ImageNet is a research training dataset with a wide variety of categories like jackfruit and syringe. This base of knowledge will help us classify cats and dogs from our specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96940f5-d23e-4736-8f83-865872e722f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ca76e-a0cb-45a1-83df-983d7a374909",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994efaa6-1842-4da7-9b32-f81de8537434",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3abd8-7510-4af3-aca8-16c2414641b2",
   "metadata": {},
   "source": [
    "### Freeze the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d1f5a-9e24-4aff-82ad-6ce71544d258",
   "metadata": {},
   "source": [
    "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's trainable flag to False will freeze all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75452c-f1c7-4766-bd08-d2ab06d611fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e345a82-5171-468e-960a-45ecbf4229db",
   "metadata": {},
   "source": [
    "When you set layer.trainable = False, the BatchNormalization layer will run in inference mode, and will not update its mean and variance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9e6da-9004-415b-8825-c47a89ad28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e92117-41c4-4534-b23d-5ab9b362181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149b712-3615-40ab-baa2-57e755f8edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5c7d2-a1a1-42e4-90b2-a70237dc8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e5152-505a-4dec-a022-58e3b12bfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7417553-9083-4f9b-a577-ec394cbcf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e771881-66bd-4a81-b8a9-b18b3aca20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ae454-57bd-47cd-bf2c-ee0b77da7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1e3e2-f525-456e-a420-f47e43cc7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbee5ab-3592-40c6-aa26-9c477cdc7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e9c8a-49a7-4071-84d1-5e1945039ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c065d-e5dd-476e-a7ec-77de3809fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb6033-0b42-44da-af24-0c3e135f8b56",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
